{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Prediction Model\n",
    "\n",
    "> **Course**: Data Mining\n",
    "\n",
    "> **Author**: Enes Kemal \n",
    "\n",
    "> **  Date**: 05/02/2017\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 0: Data Preparation and Cleaning \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0         M        17.99         10.38          122.80     1001.0   \n",
       "1         M        20.57         17.77          132.90     1326.0   \n",
       "2         M        19.69         21.25          130.00     1203.0   \n",
       "3         M        11.42         20.38           77.58      386.1   \n",
       "4         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "0         0.2419           ...                    25.38          17.33   \n",
       "1         0.1812           ...                    24.99          23.41   \n",
       "2         0.2069           ...                    23.57          25.53   \n",
       "3         0.2597           ...                    14.91          26.50   \n",
       "4         0.1809           ...                    22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV data into df\n",
    "df = pd.read_csv('./eneskemal_PredModel.csv')\n",
    "# delete id column no need\n",
    "df.drop('id',axis=1,inplace=True)\n",
    "# delete unnamed colum at the end\n",
    "df.drop('Unnamed: 32',axis=1,inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learn the unique values in diagnosis column\n",
    "df.diagnosis.unique() \n",
    "# M: Malign (Yes Cancer)\n",
    "# B: Benign (No Cancer)\n",
    "# I can also map M and B as 1 and 0 for more numerical \n",
    "#  approach\n",
    "df['diagnosis'] = df['diagnosis'].map({'M':1,'B':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Data Information and Descriptive Statistics\n",
    "---\n",
    "Generate the information about your dataset: number of columns and rows, names and data types of the columns, memory usage of the dataset. \n",
    "\n",
    "> Hint: Pandas data frame info() function.\n",
    "\n",
    "Generate descriptive statistics of all columns (input and output) of your dataset. Descriptive statistics for numerical columns include: count, mean, std, min, 25 percentile (Q1), 50 percentile (Q2, median), 75 percentile (Q3), max values of the columns. For categorical columns, determine distinct values and their frequency in each categorical column. \n",
    "\n",
    "> Hint: Pandas, data frame describe() function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 31 columns):\n",
      "diagnosis                  569 non-null int64\n",
      "radius_mean                569 non-null float64\n",
      "texture_mean               569 non-null float64\n",
      "perimeter_mean             569 non-null float64\n",
      "area_mean                  569 non-null float64\n",
      "smoothness_mean            569 non-null float64\n",
      "compactness_mean           569 non-null float64\n",
      "concavity_mean             569 non-null float64\n",
      "concave points_mean        569 non-null float64\n",
      "symmetry_mean              569 non-null float64\n",
      "fractal_dimension_mean     569 non-null float64\n",
      "radius_se                  569 non-null float64\n",
      "texture_se                 569 non-null float64\n",
      "perimeter_se               569 non-null float64\n",
      "area_se                    569 non-null float64\n",
      "smoothness_se              569 non-null float64\n",
      "compactness_se             569 non-null float64\n",
      "concavity_se               569 non-null float64\n",
      "concave points_se          569 non-null float64\n",
      "symmetry_se                569 non-null float64\n",
      "fractal_dimension_se       569 non-null float64\n",
      "radius_worst               569 non-null float64\n",
      "texture_worst              569 non-null float64\n",
      "perimeter_worst            569 non-null float64\n",
      "area_worst                 569 non-null float64\n",
      "smoothness_worst           569 non-null float64\n",
      "compactness_worst          569 non-null float64\n",
      "concavity_worst            569 non-null float64\n",
      "concave points_worst       569 non-null float64\n",
      "symmetry_worst             569 non-null float64\n",
      "fractal_dimension_worst    569 non-null float64\n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 137.9 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.372583</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.483918</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        diagnosis  radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
       "count  569.000000   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     0.372583    14.127292     19.289649       91.969033   654.889104   \n",
       "std      0.483918     3.524049      4.301036       24.298981   351.914129   \n",
       "min      0.000000     6.981000      9.710000       43.790000   143.500000   \n",
       "25%      0.000000    11.700000     16.170000       75.170000   420.300000   \n",
       "50%      0.000000    13.370000     18.840000       86.240000   551.100000   \n",
       "75%      1.000000    15.780000     21.800000      104.100000   782.700000   \n",
       "max      1.000000    28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "count     569.000000           ...               569.000000     569.000000   \n",
       "mean        0.181162           ...                16.269190      25.677223   \n",
       "std         0.027414           ...                 4.833242       6.146258   \n",
       "min         0.106000           ...                 7.930000      12.020000   \n",
       "25%         0.161900           ...                13.010000      21.080000   \n",
       "50%         0.179200           ...                14.970000      25.410000   \n",
       "75%         0.195700           ...                18.790000      29.720000   \n",
       "max         0.304000           ...                36.040000      49.540000   \n",
       "\n",
       "       perimeter_worst   area_worst  smoothness_worst  compactness_worst  \\\n",
       "count       569.000000   569.000000        569.000000         569.000000   \n",
       "mean        107.261213   880.583128          0.132369           0.254265   \n",
       "std          33.602542   569.356993          0.022832           0.157336   \n",
       "min          50.410000   185.200000          0.071170           0.027290   \n",
       "25%          84.110000   515.300000          0.116600           0.147200   \n",
       "50%          97.660000   686.500000          0.131300           0.211900   \n",
       "75%         125.400000  1084.000000          0.146000           0.339100   \n",
       "max         251.200000  4254.000000          0.222600           1.058000   \n",
       "\n",
       "       concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "count       569.000000            569.000000      569.000000   \n",
       "mean          0.272188              0.114606        0.290076   \n",
       "std           0.208624              0.065732        0.061867   \n",
       "min           0.000000              0.000000        0.156500   \n",
       "25%           0.114500              0.064930        0.250400   \n",
       "50%           0.226700              0.099930        0.282200   \n",
       "75%           0.382900              0.161400        0.317900   \n",
       "max           1.252000              0.291000        0.663800   \n",
       "\n",
       "       fractal_dimension_worst  \n",
       "count               569.000000  \n",
       "mean                  0.083946  \n",
       "std                   0.018061  \n",
       "min                   0.055040  \n",
       "25%                   0.071460  \n",
       "50%                   0.080040  \n",
       "75%                   0.092080  \n",
       "max                   0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Train Test Split\n",
    "---\n",
    "\n",
    "Split your data into Training and Test data set by randomly selecting; use 70% for training and 30 % for testing. Generate descriptive statistics of all columns (input and output) of Training and Test datasets. Review the descriptive statistics of input output columns in Train, Test and original Full (before the splitting operation) datasets and compare them to each other. Are they similar or not? Do you think Train and Test dataset are representative of the Full datasets ? why ? \n",
    "\n",
    "> Hint: Scikit learn, data train_test_split(), stratified function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.627417\n",
       "1    0.372583\n",
       "Name: diagnosis, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"diagnosis\"].value_counts(df[\"diagnosis\"].unique()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Splitting train and test data\n",
    "# .7 and .3 \n",
    "import numpy as np # Linear algebra and numerical apps\n",
    "msk = np.random.rand(len(df)) < 0.7\n",
    "train_df = df[msk]\n",
    "test_df = df[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Analysis of the Output Column\n",
    "---\n",
    "\n",
    "Analyze the output columns in Train and Test dataset. If the output column is numerical then calculate the IQR (inter quartile range, Q3-Q1) and Range (difference between max and min value). If your output column is categorical then determine if the column is nominal or ordinal, why?. Is there a class imbalance problem? (check if there is big difference between the number of distinct values in your categorical output column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.626263\n",
      "1    0.373737\n",
      "Name: diagnosis, dtype: float64\n",
      "396\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1        17.99         10.38          122.80     1001.0   \n",
       "1          1        20.57         17.77          132.90     1326.0   \n",
       "2          1        19.69         21.25          130.00     1203.0   \n",
       "3          1        11.42         20.38           77.58      386.1   \n",
       "4          1        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "0         0.2419           ...                    25.38          17.33   \n",
       "1         0.1812           ...                    24.99          23.41   \n",
       "2         0.2069           ...                    23.57          25.53   \n",
       "3         0.2597           ...                    14.91          26.50   \n",
       "4         0.1809           ...                    22.54          16.67   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0           184.60      2019.0            0.1622             0.6656   \n",
       "1           158.80      1956.0            0.1238             0.1866   \n",
       "2           152.50      1709.0            0.1444             0.4245   \n",
       "3            98.87       567.7            0.2098             0.8663   \n",
       "4           152.20      1575.0            0.1374             0.2050   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0           0.7119                0.2654          0.4601   \n",
       "1           0.2416                0.1860          0.2750   \n",
       "2           0.4504                0.2430          0.3613   \n",
       "3           0.6869                0.2575          0.6638   \n",
       "4           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                  0.11890  \n",
       "1                  0.08902  \n",
       "2                  0.08758  \n",
       "3                  0.17300  \n",
       "4                  0.07678  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df[\"diagnosis\"].value_counts(train_df[\"diagnosis\"].unique()[0]))\n",
    "print(len(train_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.630058\n",
      "1    0.369942\n",
      "Name: diagnosis, dtype: float64\n",
      "173\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.6</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>...</td>\n",
       "      <td>19.19</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.8</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>20.96</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.7</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>...</td>\n",
       "      <td>19.07</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.4</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>15.34</td>\n",
       "      <td>14.26</td>\n",
       "      <td>102.50</td>\n",
       "      <td>704.4</td>\n",
       "      <td>0.10730</td>\n",
       "      <td>0.21350</td>\n",
       "      <td>0.20770</td>\n",
       "      <td>0.09756</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>...</td>\n",
       "      <td>18.07</td>\n",
       "      <td>19.08</td>\n",
       "      <td>125.1</td>\n",
       "      <td>980.9</td>\n",
       "      <td>0.1390</td>\n",
       "      <td>0.5954</td>\n",
       "      <td>0.6305</td>\n",
       "      <td>0.23930</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>0.09946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "7           1        13.71         20.83           90.20      577.9   \n",
       "10          1        16.02         23.24          102.70      797.8   \n",
       "12          1        19.17         24.80          132.40     1123.0   \n",
       "16          1        14.68         20.13           94.74      684.5   \n",
       "22          1        15.34         14.26          102.50      704.4   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "7           0.11890           0.16450         0.09366              0.05985   \n",
       "10          0.08206           0.06669         0.03299              0.03323   \n",
       "12          0.09740           0.24580         0.20650              0.11180   \n",
       "16          0.09867           0.07200         0.07395              0.05259   \n",
       "22          0.10730           0.21350         0.20770              0.09756   \n",
       "\n",
       "    symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "7          0.2196           ...                    17.06          28.14   \n",
       "10         0.1528           ...                    19.19          33.88   \n",
       "12         0.2397           ...                    20.96          29.94   \n",
       "16         0.1586           ...                    19.07          30.88   \n",
       "22         0.2521           ...                    18.07          19.08   \n",
       "\n",
       "    perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "7             110.6       897.0            0.1654             0.3682   \n",
       "10            123.8      1150.0            0.1181             0.1551   \n",
       "12            151.7      1332.0            0.1037             0.3903   \n",
       "16            123.4      1138.0            0.1464             0.1871   \n",
       "22            125.1       980.9            0.1390             0.5954   \n",
       "\n",
       "    concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "7            0.2678               0.15560          0.3196   \n",
       "10           0.1459               0.09975          0.2948   \n",
       "12           0.3639               0.17670          0.3176   \n",
       "16           0.2914               0.16090          0.3029   \n",
       "22           0.6305               0.23930          0.4667   \n",
       "\n",
       "    fractal_dimension_worst  \n",
       "7                   0.11510  \n",
       "10                  0.08452  \n",
       "12                  0.10230  \n",
       "16                  0.08216  \n",
       "22                  0.09946  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_df[\"diagnosis\"].value_counts(test_df[\"diagnosis\"].unique()[0]))\n",
    "print(len(test_df))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Our output/classification label is diagnosis(M/B), which is nominal categorical data.**\n",
    "\n",
    "> The ratios between Benign and Malignant outputs in train and test\n",
    "are pretty similar to what we had  in the full data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Scale Training and Test Dataset\n",
    "---\n",
    "\n",
    "Using one of the scaling method (max, min-max, standard or robust), create a scaler object and scale the numerical input columns of the Training dataset. Using the same scaler object, scale the numerical input columns of the Test set. Generate the descriptive statistics of the scaled input columns of Training and Test set.\n",
    "\n",
    "If some of the input columns are categorical then convert them to binary columns using one-hotencoder() function (scikit learn) or dummy() function (Pandas data frame). \n",
    "\n",
    "> Hint: http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eneskemal/anaconda3/lib/python3.6/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# I am going to apply min-max scaling for my data.\n",
    "from sklearn import preprocessing\n",
    "# Fitting the minmax scaled version for training data\n",
    "minmax_scale = preprocessing.MinMaxScaler().fit(train_df.iloc[:, 1:])\n",
    "# Now actually scale train and test data\n",
    "train_df.iloc[:, 1:] = minmax_scale.transform(train_df.iloc[:, 1:])\n",
    "test_df.iloc[:, 1:] = minmax_scale.transform(test_df.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.522023</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.537385</td>\n",
       "      <td>0.356389</td>\n",
       "      <td>0.553970</td>\n",
       "      <td>0.792037</td>\n",
       "      <td>0.703799</td>\n",
       "      <td>0.768949</td>\n",
       "      <td>0.686364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.610409</td>\n",
       "      <td>0.141525</td>\n",
       "      <td>0.661431</td>\n",
       "      <td>0.445464</td>\n",
       "      <td>0.601136</td>\n",
       "      <td>0.619292</td>\n",
       "      <td>0.568610</td>\n",
       "      <td>0.912027</td>\n",
       "      <td>0.598462</td>\n",
       "      <td>0.418864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.652795</td>\n",
       "      <td>0.334440</td>\n",
       "      <td>0.610277</td>\n",
       "      <td>0.495838</td>\n",
       "      <td>0.220339</td>\n",
       "      <td>0.181768</td>\n",
       "      <td>0.203799</td>\n",
       "      <td>0.366806</td>\n",
       "      <td>0.379798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596155</td>\n",
       "      <td>0.303571</td>\n",
       "      <td>0.530273</td>\n",
       "      <td>0.429833</td>\n",
       "      <td>0.347553</td>\n",
       "      <td>0.154563</td>\n",
       "      <td>0.192971</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.233590</td>\n",
       "      <td>0.222878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.608191</td>\n",
       "      <td>0.478838</td>\n",
       "      <td>0.589348</td>\n",
       "      <td>0.443062</td>\n",
       "      <td>0.466746</td>\n",
       "      <td>0.431017</td>\n",
       "      <td>0.462946</td>\n",
       "      <td>0.668583</td>\n",
       "      <td>0.509596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.544258</td>\n",
       "      <td>0.360075</td>\n",
       "      <td>0.498246</td>\n",
       "      <td>0.368549</td>\n",
       "      <td>0.483590</td>\n",
       "      <td>0.385375</td>\n",
       "      <td>0.359744</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.403706</td>\n",
       "      <td>0.213433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.189011</td>\n",
       "      <td>0.442739</td>\n",
       "      <td>0.211028</td>\n",
       "      <td>0.092551</td>\n",
       "      <td>0.792844</td>\n",
       "      <td>0.811361</td>\n",
       "      <td>0.566135</td>\n",
       "      <td>0.549922</td>\n",
       "      <td>0.776263</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227761</td>\n",
       "      <td>0.385928</td>\n",
       "      <td>0.225611</td>\n",
       "      <td>0.085376</td>\n",
       "      <td>0.915472</td>\n",
       "      <td>0.814012</td>\n",
       "      <td>0.548642</td>\n",
       "      <td>0.884880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.773711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.638603</td>\n",
       "      <td>0.192116</td>\n",
       "      <td>0.626155</td>\n",
       "      <td>0.483395</td>\n",
       "      <td>0.374566</td>\n",
       "      <td>0.347893</td>\n",
       "      <td>0.464353</td>\n",
       "      <td>0.545217</td>\n",
       "      <td>0.378283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.506615</td>\n",
       "      <td>0.123934</td>\n",
       "      <td>0.496721</td>\n",
       "      <td>0.335302</td>\n",
       "      <td>0.437364</td>\n",
       "      <td>0.172415</td>\n",
       "      <td>0.319489</td>\n",
       "      <td>0.558419</td>\n",
       "      <td>0.157500</td>\n",
       "      <td>0.142595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0          1     0.522023      0.027801        0.537385   0.356389   \n",
       "1          1     0.652795      0.334440        0.610277   0.495838   \n",
       "2          1     0.608191      0.478838        0.589348   0.443062   \n",
       "3          1     0.189011      0.442739        0.211028   0.092551   \n",
       "4          1     0.638603      0.192116        0.626155   0.483395   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0         0.553970          0.792037        0.703799             0.768949   \n",
       "1         0.220339          0.181768        0.203799             0.366806   \n",
       "2         0.466746          0.431017        0.462946             0.668583   \n",
       "3         0.792844          0.811361        0.566135             0.549922   \n",
       "4         0.374566          0.347893        0.464353             0.545217   \n",
       "\n",
       "   symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "0       0.686364           ...                 0.610409       0.141525   \n",
       "1       0.379798           ...                 0.596155       0.303571   \n",
       "2       0.509596           ...                 0.544258       0.360075   \n",
       "3       0.776263           ...                 0.227761       0.385928   \n",
       "4       0.378283           ...                 0.506615       0.123934   \n",
       "\n",
       "   perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "0         0.661431    0.445464          0.601136           0.619292   \n",
       "1         0.530273    0.429833          0.347553           0.154563   \n",
       "2         0.498246    0.368549          0.483590           0.385375   \n",
       "3         0.225611    0.085376          0.915472           0.814012   \n",
       "4         0.496721    0.335302          0.437364           0.172415   \n",
       "\n",
       "   concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0         0.568610              0.912027        0.598462   \n",
       "1         0.192971              0.639175        0.233590   \n",
       "2         0.359744              0.835052        0.403706   \n",
       "3         0.548642              0.884880        1.000000   \n",
       "4         0.319489              0.558419        0.157500   \n",
       "\n",
       "   fractal_dimension_worst  \n",
       "0                 0.418864  \n",
       "1                 0.222878  \n",
       "2                 0.213433  \n",
       "3                 0.773711  \n",
       "4                 0.142595  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.305084</td>\n",
       "      <td>0.461411</td>\n",
       "      <td>0.302107</td>\n",
       "      <td>0.174848</td>\n",
       "      <td>0.558926</td>\n",
       "      <td>0.445126</td>\n",
       "      <td>0.219653</td>\n",
       "      <td>0.312859</td>\n",
       "      <td>0.573737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306337</td>\n",
       "      <td>0.429638</td>\n",
       "      <td>0.285242</td>\n",
       "      <td>0.167080</td>\n",
       "      <td>0.622268</td>\n",
       "      <td>0.330753</td>\n",
       "      <td>0.213898</td>\n",
       "      <td>0.534708</td>\n",
       "      <td>0.321506</td>\n",
       "      <td>0.393939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>0.422170</td>\n",
       "      <td>0.561411</td>\n",
       "      <td>0.392321</td>\n",
       "      <td>0.269201</td>\n",
       "      <td>0.193775</td>\n",
       "      <td>0.145114</td>\n",
       "      <td>0.077369</td>\n",
       "      <td>0.173706</td>\n",
       "      <td>0.236364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384182</td>\n",
       "      <td>0.582623</td>\n",
       "      <td>0.352346</td>\n",
       "      <td>0.229853</td>\n",
       "      <td>0.309912</td>\n",
       "      <td>0.124002</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.342784</td>\n",
       "      <td>0.272620</td>\n",
       "      <td>0.193362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>0.581834</td>\n",
       "      <td>0.626141</td>\n",
       "      <td>0.606669</td>\n",
       "      <td>0.408736</td>\n",
       "      <td>0.345822</td>\n",
       "      <td>0.694497</td>\n",
       "      <td>0.484287</td>\n",
       "      <td>0.584422</td>\n",
       "      <td>0.675253</td>\n",
       "      <td>...</td>\n",
       "      <td>0.448871</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.494179</td>\n",
       "      <td>0.275010</td>\n",
       "      <td>0.214819</td>\n",
       "      <td>0.352194</td>\n",
       "      <td>0.290655</td>\n",
       "      <td>0.607216</td>\n",
       "      <td>0.317564</td>\n",
       "      <td>0.309983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>0.354250</td>\n",
       "      <td>0.432365</td>\n",
       "      <td>0.334873</td>\n",
       "      <td>0.220587</td>\n",
       "      <td>0.358410</td>\n",
       "      <td>0.161401</td>\n",
       "      <td>0.173429</td>\n",
       "      <td>0.274909</td>\n",
       "      <td>0.265657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379797</td>\n",
       "      <td>0.502665</td>\n",
       "      <td>0.350313</td>\n",
       "      <td>0.226876</td>\n",
       "      <td>0.496797</td>\n",
       "      <td>0.155048</td>\n",
       "      <td>0.232748</td>\n",
       "      <td>0.552921</td>\n",
       "      <td>0.288587</td>\n",
       "      <td>0.177883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>0.387703</td>\n",
       "      <td>0.188797</td>\n",
       "      <td>0.390878</td>\n",
       "      <td>0.229126</td>\n",
       "      <td>0.443949</td>\n",
       "      <td>0.595424</td>\n",
       "      <td>0.487101</td>\n",
       "      <td>0.509984</td>\n",
       "      <td>0.737879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.343250</td>\n",
       "      <td>0.188166</td>\n",
       "      <td>0.358955</td>\n",
       "      <td>0.187897</td>\n",
       "      <td>0.447930</td>\n",
       "      <td>0.551183</td>\n",
       "      <td>0.503594</td>\n",
       "      <td>0.822337</td>\n",
       "      <td>0.611473</td>\n",
       "      <td>0.291355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "7           1     0.305084      0.461411        0.302107   0.174848   \n",
       "10          1     0.422170      0.561411        0.392321   0.269201   \n",
       "12          1     0.581834      0.626141        0.606669   0.408736   \n",
       "16          1     0.354250      0.432365        0.334873   0.220587   \n",
       "22          1     0.387703      0.188797        0.390878   0.229126   \n",
       "\n",
       "    smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "7          0.558926          0.445126        0.219653             0.312859   \n",
       "10         0.193775          0.145114        0.077369             0.173706   \n",
       "12         0.345822          0.694497        0.484287             0.584422   \n",
       "16         0.358410          0.161401        0.173429             0.274909   \n",
       "22         0.443949          0.595424        0.487101             0.509984   \n",
       "\n",
       "    symmetry_mean           ...             radius_worst  texture_worst  \\\n",
       "7        0.573737           ...                 0.306337       0.429638   \n",
       "10       0.236364           ...                 0.384182       0.582623   \n",
       "12       0.675253           ...                 0.448871       0.477612   \n",
       "16       0.265657           ...                 0.379797       0.502665   \n",
       "22       0.737879           ...                 0.343250       0.188166   \n",
       "\n",
       "    perimeter_worst  area_worst  smoothness_worst  compactness_worst  \\\n",
       "7          0.285242    0.167080          0.622268           0.330753   \n",
       "10         0.352346    0.229853          0.309912           0.124002   \n",
       "12         0.494179    0.275010          0.214819           0.352194   \n",
       "16         0.350313    0.226876          0.496797           0.155048   \n",
       "22         0.358955    0.187897          0.447930           0.551183   \n",
       "\n",
       "    concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "7          0.213898              0.534708        0.321506   \n",
       "10         0.116534              0.342784        0.272620   \n",
       "12         0.290655              0.607216        0.317564   \n",
       "16         0.232748              0.552921        0.288587   \n",
       "22         0.503594              0.822337        0.611473   \n",
       "\n",
       "    fractal_dimension_worst  \n",
       "7                  0.393939  \n",
       "10                 0.193362  \n",
       "12                 0.309983  \n",
       "16                 0.177883  \n",
       "22                 0.291355  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5: Build Predictive Model\n",
    "---\n",
    "Using one of the methods (K-Nearest Neighbor, NaÃ¯ve Bayes, Neural Network, Support Vector Machines, Decision Tree), build your predictive model using the scaled input columns of Training set. You can use any value for the model parameters, or use the default values. In building your model, use k-fold crossvalidation. \n",
    "\n",
    "> Hint: \n",
    "- http://scikit-learn.org/stable/supervised_learning.html#supervised-learning , \n",
    "- http://scikit-learn.org/stable/modules/cross_validation.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input and Output\n",
    "inp_train = train_df.iloc[:, 1:] \n",
    "out_train = train_df[\"diagnosis\"]\n",
    "inp_test = test_df.iloc[:, 1:] \n",
    "out_test = test_df[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95        0.9         0.9         0.875       0.975       0.95        0.975\n",
      "  0.975       0.97368421  0.97368421]\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes:\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "nb_model = GaussianNB() \n",
    "out_test_pred = nb_model.fit(inp_train, out_train).predict(inp_test)\n",
    "\n",
    "# Cross validation score of my model\n",
    "nb_model_scores = cross_val_score(nb_model, inp_train, out_train, cv=10, scoring='accuracy')\n",
    "print(nb_model_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Model Predictions on Training Dataset\n",
    "---\n",
    "\n",
    "Apply your model to input (scaled) columns of Training dataset to obtain the predicted output for Training dataset. If your model is regression then plot actual output versus predicted output column of Training dataset. If your model is classification then generate confusion matrix on actual and predicted columns of Training dataset. \n",
    "\n",
    "> Hint: Matplotlip, Seaborn, Bokeh scatter(), plot() functions\n",
    "- http://scikit-learn.org/0.15/auto_examples/plot_confusion_matrix.html\n",
    "- http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   1]\n",
      " [  8  56]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAFnCAYAAADAN8KoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHspJREFUeJzt3X9YlfX9x/HXQUTEn0AeHJa26fqtxcwVmlMUh1QWywqi\nWD/sKs2fzQpUhr9/kC2XpkldhQ6lULR0pUJtscv2PZGmC3KrlnU5NUUgkeS3cL5/tJ0rUsD7yOH2\n5jwfu851ce7D+XzerKu99v7cn/u+bU6n0ykAAHDefMwuAAAAqyE8AQAwiPAEAMAgwhMAAIMITwAA\nDCI8AQAwiPCE5TidTqWnp+v2229XVFSUIiMjNW/ePH333XcXNO5TTz2lESNGaPfu3Ya/W1BQoAkT\nJlzQ/K1tx44dOn369Dk/+8Mf/qDXX3+9jSsC2g8b13nCapYvX66PPvpIL774okJCQlRZWanFixfr\n66+/1saNG2Wz2dwa9+qrr1ZOTo769u3byhWbY+zYsVq3bp169+5tdilAu0PnCUspKytTRkaGli1b\nppCQEElSQECAUlJS9Oijj8rpdKqmpkYpKSmKiopSdHS0li1bpvr6eknSqFGj9MYbb+juu+/WLbfc\nomXLlkmSEhIS1NDQoAkTJuhvf/ubRo0apb1797rm/d/7M2fOaM6cOYqKitKYMWM0ZcoUnT59Wvn5\n+RozZowkuTX/jyUkJOjll19WbGysbr75Zm3cuFFr1qzR2LFjdeutt+rw4cOSpK+++kr33XefoqOj\nNWbMGL399tuSpFmzZunrr79WQkKC9u7dq6SkJC1dulTjxo3Tzp07lZSUpDVr1qigoEAjR45URUWF\nJGnt2rWaNm1aa/9jA9odwhOW8sknn6h3797q379/o+OdOnXSqFGj5OPjo/Xr1+v48eN655139Oab\nb2rv3r2uUJGkPXv2KCsrS1u2bNGGDRt0/PhxZWRkSJIyMjI0YsSIJuf/4IMPdOTIEe3atUu5ubka\nMGCA9u/f3+h33Jn/XPbs2aONGzdq6dKlWr58uXr37q1du3ZpwIAB2rJliyTp2WefVUREhHbu3Kkl\nS5Zozpw5qqur09KlS11/z4033ihJcjgcys7OVnR0tGuOQYMGKTIyUmlpaSoqKlJmZqaSk5Nb/OcA\neDvCE5ZSVlam4ODgZn8nLy9P9957r3x9feXv769x48bp73//u+vzcePGqUOHDgoJCVFwcLCOHTt2\n3vMHBQXp4MGDevfdd1VVVaUZM2Zo+PDhHpk/IiJCvr6+uuKKK1RVVaWoqChJ0hVXXKETJ05Iktas\nWeM61zp48GDV1NSouLj4nOOFh4erU6dOZx1/8skntWvXLs2aNUtPPPGE7Hb7ef/3AXgrwhOWEhgY\nqKKiomZ/59tvv1WPHj1c73v06KHS0lLX+65du7p+7tChg2tJ9XwMGjRIycnJysjI0LBhwzRz5kyV\nl5d7ZP4uXbq4fueH7318fNTQ0CBJ2r17t+6//35FRUXp1ltvldPpdH32Yz+s6cfzREdH6+OPP9a4\nceOa/fsBfI/whKXccMMNKi0t1YEDBxodr6ur04oVK1RVVaVLLrlEZWVlrs/Kysp0ySWXGJrnhwEl\nSadOnXL9PHbsWGVkZOj9999XVVWVXn311UbfbY35z0ddXZ1mzJihSZMmKScnR9u3b3drs1RRUZH+\n/Oc/67bbbtOLL77Y6nUC7RHhCUvp3r27Hn30USUmJurQoUOSpKqqKqWkpOif//ynOnfurJEjRyo7\nO1v19fWqrKzUtm3bmj2PeS69evXSZ599Jun7Sz5qamokSVu2bNHq1aslST179tTPfvazs77bGvOf\nj6qqKlVWVuq6666T9P251o4dO6qyslKS5Ovre1ZXfC6LFy/Wo48+qtmzZ2vnzp3617/+1eq1Au0N\n4QnLmTp1qu69915NmjRJUVFRuuuuuxQcHOzqmhISEtS7d2/ddtttGj9+vEaOHNlok8z5eOKJJ7Ru\n3TrdfvvtOnjwoAYMGCBJGj16tA4cOKBf//rXio6O1pdffqmHH3640XdbY/7z8b//IxETE6OYmBj1\n7dtXkZGRmjhxoiorKzV27FjFxcVpx44dTY6Rl5enI0eOKC4uTl27dtWTTz6p5ORkQ0vZgDfiOk8A\nAAyi8wQAwCDCEwAAgwhPAAAMIjwBADCI8AQAwCBfswtoyqB+rX9dHNDW9hZuNbsEoFX4dW/+tpgX\n4kL+977g0N9asZLzd9GGJwDAO7j7GEEzsWwLAIBBdJ4AAFPZbNbr46xXMQAAJqPzBACYykfWO+dJ\neAIATGXFDUOEJwDAVD4WPOdJeAIATGXFztN6cQ8AgMkITwAADGLZFgBgKhu7bQEAMIYNQwAAGGTF\nDUOEJwDAVD4WDE/r9coAAJiM8AQAwCCWbQEAprJZsI8jPAEAprLihiHrxT0AoF3xsdncfrXkiy++\nUGRkpDZs2CBJOnbsmBISEhQfH6/p06ertrZWkrR9+3aNHz9e99xzjzZv3txyzRf2JwMAcGFsF/Cf\n5lRWVmrhwoUKDw93HVu5cqXi4+OVmZmpfv36KTs7W5WVlVq9erXWrVunjIwMrV+/XmVlZc2OTXgC\nANolPz8/vfLKK7Lb7a5j+fn5Gj16tCQpIiJCDodDn3zyiQYOHKhu3brJ399fv/jFL7Rv375mx+ac\nJwCgXfL19ZWvb+OYq6qqkp+fnyQpODhYxcXFKikpUVBQkOt3goKCVFxc3PzYrV8uAADnz6zb8zmd\nTkPHf4hlWwCAqWw2m9svowICAlRdXS1JKioqkt1ul91uV0lJiet3Tpw40Wip91wITwCAqTy52/bH\nhg4dqpycHElSbm6uhg8fruuvv16FhYUqLy9XRUWF9u3bpxtvvLHZcVi2BQCYylOPJPv000+Vmpqq\no0ePytfXVzk5OXruueeUlJSkrKwshYaGKiYmRh07dtTMmTM1YcIE2Ww2TZ48Wd26dWu+Zuf5LO6a\nYFC/EWaXAFywvYVbzS4BaBV+3YM9NnbUdfe6/d2cTze1YiXnj84TAGAqKz7P03oVAwBgMjpPAICp\nrHhvW8ITAGAqKz4Mm/AEAJjKU7ttPYlzngAAGETnCQAwFec8AQAwyIrnPFm2BQDAIDpPAICprLhh\niPAEAJiKOwwBAOAF6DwBAKZity0AAAZZcbct4QkAMJUVNwxxzhMAAIPoPAEAprLisi2dJwAABtF5\nAgBMxW5bAAAMsuKyLeEJADCVFXfbEp4AAFNZsfNkwxAAAAYRngAAGMSyLQDAVOy2BQDAICue8yQ8\nAQCmYrctAAAGWbHzZMMQAAAGEZ4AABjEsi0AwFTstgUAwCArnvMkPAEApqLzBADAICteqsKGIQAA\nDKLzBACYysd6jSedJwAARtF5AgBMxYYhAAAM4lIVAAAMsmLnyTlPAAAMovMEAJjKx4LXeRKeAABT\nsWwLAIAX8GjnWVFRoZKSEklSr169FBAQ4MnpAAAWxG7b/yosLNTixYtVXl6uwMBAOZ1OnThxQiEh\nIUpJSdGVV17piWkBABZkwez0THguWbJEixcvVv/+/RsdP3DggBYsWKCNGzd6YloAAFwqKiqUmJio\nU6dOqa6uTpMnT9aAAQP0zDPPqL6+Xr169dLy5cvl5+dneGyPhKfT6TwrOCXp2muvVX19vSemBABY\nlKeWbd9880399Kc/1cyZM1VUVKQHH3xQYWFhio+PV3R0tJ5//nllZ2crPj7e8NgeCc/rr79eEydO\nVGRkpIKCgiRJJSUlysnJ0S9/+UtPTAkAsChPPZIsMDBQn3/+uSS5TiPm5+dr/vz5kqSIiAi99tpr\nF094zpo1S3v27JHD4VBBQYEkyW63a8qUKQoLC/PElAAAi/LUpSq33Xabtm7dqjFjxqi8vFxpaWma\nNGmSa5k2ODhYxcXFbo3tsd22Q4YM0ZAhQzw1PAAAzdq2bZtCQ0P16quv6rPPPtPs2bMbfe50Ot0e\nm5skAABM5alznvv27dMtt9wiSbrqqqt04sQJde7cWdXV1fL391dRUZHsdrtbY3OTBACAqWw291/N\n6devnz755BNJ0tGjR9WlSxcNGzZMOTk5kqTc3FwNHz7crZrpPAEA7VJsbKxmz56tBx54QGfOnNG8\nefPUv39/JSYmKisrS6GhoYqJiXFrbMITAGAqTy3bdunSRS+88MJZx9PT0y94bMITAGAqT12q4kmE\nJwDAVFa8ty0bhgAAMIjOEwBgKgs2nnSeAAAYRecJADCVp27P50mEJwDAVFbcMER4AgBMZcHsJDwB\nAOayYufJhiEAAAwiPAEAMIhlWwCAqbg9HwAABnGpCgAABvlYLzsJTwCAuazYebJhCAAAgwhPAAAM\nYtkWAGAqKy7bEp4AAFOxYQgAAIPoPAEAMMiC2cmGIQAAjKLzBACYiqeqAADgBeg8AQCm4sbwAAAY\nZMFVW8ITAGAuznkCAOAF6DwBAKbiJgkAABhkwexk2RYAAKPoPAEApmLZFgAAg6z4VBWWbQEAMIjO\nEwBgKpZtAQAwyILZSXgCAMzFHYYAAPACdJ4AAFNZ8ZwnnScAAAbReQIATGXBxpPwBACYy4rLtoQn\nAMBUFszOpsMzOzu72S/efffdrV4MAMD7WPFSlSbD8+OPP272i4QnAMBbNRmeS5cudf3c0NCg0tJS\n9erVq02KAgDgYtbipSoOh0ORkZFKSEiQJC1ZskR5eXmergsA4CVsNvdfZmkxPFesWKFNmza5us6J\nEydqzZo1Hi8MAOAdbDab26+WbN++XXfccYfuuusu5eXl6dixY0pISFB8fLymT5+u2tpat2puMTwD\nAgJ0ySWXuN4HBQWpY8eObk0GAMCPearzPHnypFavXq3MzEytXbtWf/nLX7Ry5UrFx8crMzNT/fr1\na3FzbFNaDE9/f3999NFHkqRTp04pMzNTnTp1cmsyAAB+zFOdp8PhUHh4uLp27Sq73a6FCxcqPz9f\no0ePliRFRETI4XC4VXOL13nOnTtX8+bNU2FhocaMGaPBgwdrwYIFbk0GAEBbOXLkiKqrqzVx4kSV\nl5dr6tSpqqqqkp+fnyQpODhYxcXFbo3dYnj+5Cc/UVpamluDAwBgprKyMr344ov65ptv9Nvf/lZO\np9P12Q9/NqrFZds9e/Zo/PjxuuGGGxQWFqbY2NgWrwEFAOB8eeqcZ3BwsMLCwuTr66u+ffuqS5cu\n6tKli6qrqyVJRUVFstvtbtXcYnguWLBATz31lPLz8+VwODRt2jTNnz/frckAAPgxH5vN7Vdzbrnl\nFn344YdqaGjQyZMnVVlZqaFDhyonJ0eSlJubq+HDh7tVc4vLtsHBwQoPD3e9HzZsmEJDQ92aDACA\nH/PU9ZohISGKiorSvffeK0lKTk7WwIEDlZiYqKysLIWGhiomJsatsZsMz8OHD0uSBg4cqNdee01D\nhw6Vj4+PHA6HrrnmGrcmAwDgxzz5VJW4uDjFxcU1Opaenn7B4zYZng8++KBsNpvrhOqGDRtcn9ls\nNk2bNu2CJwcAwIqaDM+//vWvTX5p3759HikGAOB9LPhQlZbPeZ4+fVrbtm3TyZMnJUl1dXXasmWL\nPvjgA48XBwDAxajF3bYzZszQ559/rq1bt6qiokLvv/++5s2b1walAQC8gSfvbespLYZnTU2NFixY\noD59+igxMVF/+tOftHPnzraoDQDgBaz4VJUWl23r6upUWVnpuk4mMDDQtRMXAIALZWYH6a4Ww/PO\nO+/Upk2bdM899+jWW29VUFCQ+vbt2xa1AQBwUWoxPO+77z7Xz+Hh4SotLeU6TwBAq7Fg49l0eL7w\nwgtNfundd9/V9OnTPVIQAMC7tKtl2w4dOrRlHQAAWEaT4TllypS2rAMA4KUs2Hi2fM7TLP+3+1Wz\nSwAu2Lvz3jC7BKBV3Pb8ZI+N3dLTUS5GF214AgC8gwWzs+WbJEjSyZMnVVhYKElqaGjwaEEAAFzs\nWgzPt99+W7GxsZo1a5YkaeHChdq8ebPHCwMAeId2eXu+9PR0bdu2TYGBgZKkxMREbdq0yeOFAQC8\ngxVvz9dieHbr1k2dO3d2vff391fHjh09WhQAABezFjcMBQYG6s0331RNTY0OHDigHTt2KCgoqC1q\nAwB4AZuP9XYMtdh5zp8/X4WFhaqoqFBycrJqamq0aNGitqgNAOAFrLhs22Ln2b17d6WkpLRFLQAA\nWEKL4TlixIhz7mjKy8vzRD0AAC/Tru5t+z+ZmZmun+vq6uRwOFRTU+PRogAA3sOC2dlyePbp06fR\n+8svv1wTJkzQQw895KmaAABepF12ng6Ho9H748eP6z//+Y/HCgIA4GLXYniuWbPG9bPNZlPXrl01\nf/58jxYFAPAeFmw8Ww7PpKQkXXvttW1RCwAAltDidZ6pqaltUQcAwFtZ8ELPFjvP0NBQJSQk6Prr\nr290W77p06d7tDAAgHdolxuGLr30Ul166aVtUQsAwAtZMDubDs/t27frjjvu0JQpU9qyHgCAl2lX\n97bNzs5uyzoAALCMFjcMAQCAxppctt2/f79Gjhx51nGn0ymbzca9bQEAraJdnfO85ppr9Pzzz7dl\nLQAAL9Sudtv6+fmddV9bAABamwWzs+nwHDRoUFvWAQDwUlbsPJvcMPT000+3ZR0AAFgGu20BADCo\nxTsMAQDgSRZctSU8AQDmsuI5T8ITAGAuC55AJDwBAKayYudpwbwHAMBchCcAAAaxbAsAMJUFV20J\nTwCAuax4zpPwBACYyoLZyTlPAIDJbDb3X+ehurpakZGR2rp1q44dO6aEhATFx8dr+vTpqq2tdatk\nwhMA0K699NJL6tGjhyRp5cqVio+PV2Zmpvr166fs7Gy3xiQ8AQCmsvnY3H615ODBg/ryyy81cuRI\nSVJ+fr5Gjx4tSYqIiJDD4XCrZsITANBupaamKikpyfW+qqpKfn5+kqTg4GAVFxe7NS4bhgAApvLU\nhqG33npLN9xwgy677LJzfu50Ot0em/AEAJjKU5eq5OXl6fDhw8rLy9Px48fl5+engIAAVVdXy9/f\nX0VFRbLb7W6NTXgCAEzlqc7zj3/8o+vnVatWqU+fPtq/f79ycnJ05513Kjc3V8OHD3drbM55AgC8\nxtSpU/XWW28pPj5eZWVliomJcWscOk8AgLna4C4JU6dOdf2cnp5+weMRngAAU53PJScXG5ZtAQAw\niM4TAGAqK97blvAEAJjLgunJsi0AAAbReQIATGXBxpPwBACYy4q7bQlPAICpPHV7Pk/inCcAAAbR\neQIAzGW9xpPOEwAAo+g8AQCmsuI5T8ITAGAqwhMAAKMseAKR8AQAmMqKnacF8x4AAHMRngAAGMSy\nLQDAVFZctiU8AQDmsl52Ep4AAHNxY3gAAIyy4LItG4YAADCI8AQAwCCWbQEAprLgqi3hCQAwF5eq\nAABglAV327b5Oc/y8vK2nhIAcBGz2Wxuv8zS5uE5ZcqUtp4SAIBW5ZFl240bNzb5WVFRkSemBABY\nlfVWbT0TnuvWrVN4eLjsdvtZn505c8YTUwIA0GY8Ep6rV6/WokWLlJycLD8/v0af5efne2JKAIBF\nsdv2v6644gqlpaXJ1/fs4ZOSkjwxJQDAori37Q907tz5nMevvfZaT00JALAiOk8AAIyx4rIt97YF\nAMAgOk8AgLms13jSeQIAYBSdJwDAVOy2BQDAKAtuGCI8AQCmYrctAABegM4TAGAuznkCAGAMy7YA\nAHgBOk8AgLms13gSngAAc7FsCwCAF6DzBACYy4O7bZ999ll9/PHHOnPmjB5//HENHDhQzzzzjOrr\n69WrVy8tX75cfn5+hsclPAEApvLUsu2HH36of//738rKytLJkyf1m9/8RuHh4YqPj1d0dLSef/55\nZWdnKz4+3vDYLNsCAMxls7n/asaQIUP0wgsvSJK6d++uqqoq5efna/To0ZKkiIgIORwOt0omPAEA\n7VKHDh0UEBAgScrOztavfvUrVVVVuZZpg4ODVVxc7NbYhCcAwFQ2m83t1/l47733lJ2drZSUlEbH\nnU6n2zUTngCAdmv37t1au3atXnnlFXXr1k0BAQGqrq6WJBUVFclut7s1LuEJADCXj839VzO+++47\nPfvss0pLS1PPnj0lSUOHDlVOTo4kKTc3V8OHD3erZHbbAgBM5andtjt27NDJkyc1Y8YM17Fly5Yp\nOTlZWVlZCg0NVUxMjFtjE54AAHN5KDxjY2MVGxt71vH09PQLHpvwBACYymbBR5JxzhMAAIMITwAA\nDGLZFgBgLgs+VYXwBACYyoqPJCM8AQDmIjwBADCG3bYAAHgBwhMAAINYtgUAmItzngAAGER4AgBg\nDJeqAABgFLttAQBo/+g8AQCmstms18dZr2IAAExG5wkAMBcbhgAAMIbdtgAAGMVuWwAA2j86TwCA\nqVi2BQDAKAuGJ8u2AAAYROcJADCXBW+SQHgCAExlY7ctAADtH50nAMBcFtwwRHgCAEzFpSoAABhl\nwQ1D1qsYAACT0XkCAEzFblsAALwAnScAwFxsGAIAwBh22wIAYJQFd9sSngAAc7FhCACA9o/wBADA\nIJZtAQCmYsMQAABGsWEIAABj6DwBADDKgp2n9SoGAMBkhCcAAAaxbAsAMJUVn6pCeAIAzMWGIQAA\njLFZcMMQ4QkAMJcFO0+b0+l0ml0EAABWYr1eGQAAkxGeAAAYRHgCAGAQ4QkAgEGEJwAABhGeAAAY\nRHh6qSVLlig2NlZxcXEqKCgwuxzAbV988YUiIyO1YcMGs0uBF+EmCV7oo48+0qFDh5SVlaWDBw9q\n9uzZysrKMrsswLDKykotXLhQ4eHhZpcCL0Pn6YUcDociIyMlSf3799epU6d0+vRpk6sCjPPz89Mr\nr7wiu91udinwMoSnFyopKVFgYKDrfVBQkIqLi02sCHCPr6+v/P39zS4DXojwhLhDIwAYQ3h6Ibvd\nrpKSEtf7EydOqFevXiZWBADWQnh6oWHDhiknJ0eSdODAAdntdnXt2tXkqgDAOniqipd67rnntHfv\nXtlsNs2dO1dXXXWV2SUBhn366adKTU3V0aNH5evrq5CQEK1atUo9e/Y0uzS0c4QnAAAGsWwLAIBB\nhCcAAAYRngAAGER4AgBgEOEJAIBBhCfalSNHjui6665TQkKCEhISFBcXp5kzZ6q8vNztMTdv3qyk\npCRJ0pNPPqmioqImf3ffvn06fPjweY995swZXXnllWcdX7VqlVasWNHsd0eNGqVDhw6d91xJSUna\nvHnzef8+gKYRnmh3goKClJGRoYyMDL3xxhuy2+166aWXWmXsFStWKCQkpMnPt27daig8AVgTjyRD\nuzdkyBDXI9dGjRql6OhoHT58WCtXrtSOHTu0YcMGOZ1OBQUFadGiRQoMDNTGjRv1+uuvq3fv3o2e\n2DFq1Cilp6frsssu06JFi/Tpp59Kkh5++GH5+vpq165dKigo0KxZs9SvXz/Nnz9fVVVVqqys1O9+\n9zsNHTpUX331lZ5++ml17txZN910U4v1Z2Zmatu2berYsaM6deqkFStWqHv37pK+74oLCwtVWlqq\n3//+97rpppv0zTffnHNeAK2H8ES7Vl9fr3fffVeDBw92Hbv88sv19NNP69ixY1q7dq2ys7Pl5+en\n9evXKy0tTZMnT9bKlSu1a9cuBQYGatKkSerRo0ejcbdv366SkhJt2rRJ5eXleuqpp/TSSy/p6quv\n1qRJkxQeHq7HHntMjzzyiG6++WYVFxcrNjZWubm5Wr16tcaPH6/4+Hjl5ua2+DfU1NTo1VdfVdeu\nXZWSkqLt27frgQcekCT17NlT69evl8PhUGpqqrZu3ap58+adc14ArYfwRLvz7bffKiEhQZLU0NCg\nG2+8UQ899JDr87CwMEnS/v37VVxcrAkTJkiSamtrdemll+rQoUPq06eP67FtN910kz777LNGcxQU\nFLi6xu7du+vll18+q478/HxVVFRo9erVkr5/fFZpaam++OILPfbYY5Kkm2++ucW/p2fPnnrsscfk\n4+Ojo0ePNrqJ/7Bhw1x/05dfftnsvABaD+GJdud/5zyb0rFjR0nfP0h50KBBSktLa/R5YWGhbDab\n631DQ8NZY9hstnMe/yE/Pz+tWrVKQUFBjY47nU75+Hy/3aC+vr7ZMY4fP67U1FS98847Cg4OVmpq\n6ll1/HjMpuYF0HrYMASvNXDgQBUUFLgeBL5z506999576tu3r44cOaLy8nI5nU45HI6zvhsWFqbd\nu3dLkr777jvdc889qq2tlc1mU11dnSRp8ODB2rlzp6Tvu+HFixdLkvr3769//OMfknTOsX+otLRU\ngYGBCg4OVllZmT744APV1ta6Pv/www8lfb/L9+c//3mz8wJoPXSe8FohISGaM2eOHn/8cXXu3Fn+\n/v5KTU1Vjx49NHHiRN1///3q06eP+vTpo+rq6kbfjY6O1r59+xQXF6czZ87okUcekZ+fn4YNG6a5\nc+dq9uzZmjNnjlJSUvTOO++otrZWkyZNkiRNnjxZiYmJ2rVrl8LCwuTr2/S/hldffbX69eunu+++\nW3379tW0adM0b948jRgxQpJUVlamxx9/XN98843mzp0rSU3OC6D18FQVAAAMYtkWAACDCE8AAAwi\nPAEAMIjwBADAIMITAACDCE8AAAwiPAEAMIjwBADAoP8HTyXwNz06eSEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22b660e240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style='darkgrid')\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(out_test, out_test_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Show confusion matrix in a separate window\n",
    "sns.heatmap(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Model Predictions on Test Dataset\n",
    "---\n",
    "Apply your model to input (scaled) columns of Test dataset to obtain the predicted output for Test dataset. If your model is regression then plot actual output versus predicted output column of Test dataset. If your model is classification then generate confusion matrix on actual and predicted columns of Test dataset. \n",
    "\n",
    "> Hint: Matplotlip, Seaborn, Bokeh scatter(), plot() functions\n",
    "- http://scikit-learn.org/0.15/auto_examples/plot_confusion_matrix.html\n",
    "- http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[108   1]\n",
      " [  8  56]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAc8AAAFnCAYAAADAN8KoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22b83e0a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(out_test, out_test_pred)\n",
    "\n",
    "print(cm)\n",
    "\n",
    "# Show confusion matrix in a separate window\n",
    "sns.heatmap(cm)\n",
    "plt.title('Confusion matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 8. Model Performance\n",
    "---\n",
    "Using one of the error (evaluation) metrics (classification or regression), calculate the performance of the model on Training set and Test set. Compare the performance of the model on Training and Test set. Which one (Training or Testing performance) is better, is there an overfitting case, why ?. Would you deploy (Productionize) this model for using in actual usage in your business system? why ? \n",
    "\n",
    "**Classification Metrics: Accuracy, Precision, Recall, F-score, Recall, AUC, ROC etc Regression Metrics: RMSE, MSE, MAE, R2 etc**\n",
    "\n",
    "- http://scikit-learn.org/stable/model_selection.html#model-selection\n",
    "- http://scikit-learn.org/stable/modules/model_evaluation.html#classification-report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfYAAAFnCAYAAABU0WtaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22b83e0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I would like to use ROC\n",
    "# Area under ROC Curve (or AUC for short) is \n",
    "#  a performance metric for binary classification problems.\n",
    "from sklearn.metrics import roc_curve\n",
    "fpr, tpr,thresholds = roc_curve(out_test, out_test_pred)\n",
    "plt.plot(fpr,tpr, label=\"Naive Bayes\")\n",
    "plt.xlim([0.0,1.0])\n",
    "plt.ylim([0.0,1.0])\n",
    "plt.title('ROC curve for Cancer classifer')\n",
    "plt.xlabel('False positive rate (1-specificity)')\n",
    "plt.ylabel('True positive rate (sensitivity)')\n",
    "plt.legend(loc=4,)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 9. Update the Model\n",
    "---\n",
    "Go back to Step5, and choose different values of the model parameters and re-train the model. Repeat Steps: 6 and 7. Using the same error metric, generate the accuracy of the model on Training and Test dataset. Did you get a better performance on Training or Test set? Explain why the new model performs better or worse than the former model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 10. Change the Error Metric\n",
    "---\n",
    "Choose another error metric other than you used in Step 8 and evaluate the performance of the model on Training and Test dataset by generating the accuracy of the model based on the new metric. Compare the results and explain which error metric is better for your modeling and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
